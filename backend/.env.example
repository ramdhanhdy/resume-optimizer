# API Keys
OPENROUTER_API_KEY=your_openrouter_api_key_here
EXA_API_KEY=your_exa_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Provider-specific API keys
LONGCAT_API_KEY=your_longcat_api_key_here
ZENMUX_API_KEY=your_zenmux_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
CEREBRAS_API_KEY=your_cerebras_api_key_here

# Vertex AI Configuration (for Claude via Vertex)
VERTEX_PROJECT_ID=your_gcp_project_id_here
VERTEX_LOCATION=us-central1

# Database
DATABASE_PATH=./data/applications.db

# Server Configuration
PORT=8000
HOST=0.0.0.0

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Per-agent model environment variables
DEFAULT_MODEL=gemini::gemini-2.5-pro
ANALYZER_MODEL=gemini::gemini-2.5-pro
OPTIMIZER_MODEL=openrouter::openai/gpt-5.1
IMPLEMENTER_MODEL=zenmux::anthropic/claude-sonnet-4.5
INSIGHT_MODEL=openrouter::x-ai/grok-4-fast
POLISH_MODEL=openrouter::anthropic/claude-sonnet-4.5
VALIDATOR_MODEL=openrouter::gemini::gemini-2.5-pro
PROFILE_MODEL=openrouter::anthropic/claude-sonnet-4.5

# Per-agent temperature settings (0.0-2.0 depending on provider)
ANALYZER_TEMPERATURE=0.6
OPTIMIZER_TEMPERATURE=1
IMPLEMENTER_TEMPERATURE=0.6
VALIDATOR_TEMPERATURE=0.2
PROFILE_TEMPERATURE=0.6
POLISH_TEMPERATURE=0.7

# Development-only flags (do NOT enable in production)
# When set to true, bypasses free-run rate limiting for local testing.
# Default is false, meaning limits remain enforced.
DEV_MODE=false
