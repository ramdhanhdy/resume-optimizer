# AI Resume Optimizer

A full-stack AI-powered resume optimization application that uses a deterministic sequential multi-agent system to analyze job requirements and tailor resumes with ethical accuracy while maintaining professional authenticity.

## ğŸ¤– Agent System Architecture

### Sequential Multi-Agent Pipeline

The application implements a **deterministic sequential pattern** where each agent builds upon the previous agent's output:

```
Profile Agent (Optional) â†’ Agent 1 â†’ Agent 2 â†’ Agent 3 â†’ Agent 4 â†’ Agent 5 â†’ Renderer
```

**Agent Pipeline:**

- **ğŸ” Profile Agent** (Optional) - Builds context from LinkedIn/GitHub
- **ğŸ“‹ Agent 1** - Job Analysis: Extracts requirements, role signals, and keywords from job postings
- **ğŸ¯ Agent 2** - Resume Optimizer: Generates targeted optimization strategy using evidence-based analysis
- **âš™ï¸ Agent 3** - Optimizer Implementer: Applies strategic changes to the candidate's resume
- **âœ… Agent 4** - Validator: Evaluates optimized resume with scoring and red flag analysis
- **âœ¨ Agent 5** - Polish: Applies validator recommendations for final refinement and generates DOCX-ready output

### Real-Time Insight Extraction

The system includes a parallel insight extraction pipeline that provides real-time streaming updates:
- **Event Persistence**: All agent events are stored in SQLite for replay and recovery
- **Reconnection Support**: Clients can reconnect and resume from the last known event
- **Parallel Processing**: Insight extraction runs asynchronously alongside agent execution
- **Chunk Streaming**: Agent outputs are streamed in real-time with configurable throttling

### Agent Responsibilities

- **ğŸ” Profile Agent** (Optional)
  - Builds evidence-backed profile index from LinkedIn/GitHub
  - Provides contextual enrichment for subsequent agents
  - Location: `backend/src/agents/profile_agent.py`
  - Note: Runs before main pipeline if LinkedIn URL or GitHub username provided

- **ğŸ“‹ Agent 1 â€” Job Analyzer**
  - Extracts requirements, role signals, and keywords from job postings
  - Identifies key competencies and qualifications needed
  - Location: `backend/src/agents/job_analyzer.py`

- **ğŸ¯ Agent 2 â€” Strategy Generator**
  - Generates targeted optimization strategy using job analysis
  - Creates evidence-based improvement plan
  - Location: `backend/src/agents/resume_optimizer.py`

- **âš™ï¸ Agent 3 â€” Resume Builder**
  - Applies the optimization strategy to build the enhanced resume
  - Implements strategic changes while preserving authenticity
  - Location: `backend/src/agents/optimizer_implementer.py`

- **âœ… Agent 4 â€” Validator**
  - Evaluates optimized resume against job posting
  - Produces multi-dimensional scoring and red flag analysis
  - Ensures accuracy and ethical compliance
  - Location: `backend/src/agents/validator.py`

- **âœ¨ Agent 5 â€” Polish**
  - Applies validator recommendations for final refinement
  - Generates DOCX-ready output with page formatting guidance
  - Ensures professional presentation
  - Location: `backend/src/agents/polish.py`

- **ğŸ“„ Renderer** (Zero-cost utility)
  - Converts final output to downloadable formats
  - Handles final document formatting
  - Location: `backend/src/agents/renderer.py`

- **ğŸ”— GitHub Projects Agent** (Separate Service)
  - Curates relevant GitHub projects for evidence-backed achievements
  - Available as separate API endpoint, not in main pipeline
  - Location: `backend/src/agents/github_projects_agent.py`

### Design Patterns Implemented

- **Sequential Multi-Agent Pattern**: Fixed linear order with context preservation
- **Generator-Critic Pattern**: Validator reviews and critiques without iterative loops
- **Human-in-the-Loop**: User checkpoints for input validation and approvals
- **Custom Logic Pattern**: Optional branches and per-agent model selection

### Orchestration Features

- **Deterministic Execution**: Fixed sequence ensures reproducible results
- **Context Engineering**: Each agent receives structured inputs from prior steps
- **Provider Routing**: Multi-provider facade selects optimal API per agent
- **Streaming Support**: Real-time progress updates via Server-Sent Events
- **Evidence Preservation**: Reduces hallucination through context chaining

## Features

### Core Agent Pipeline
- ğŸ¤– **5-Agent AI Pipeline**: Sequential processing with job analysis, strategy generation, implementation, validation, and polishing
- ğŸ” **Profile Enrichment**: Optional LinkedIn/GitHub integration for enhanced context
- ğŸ“Š **Multi-dimensional Validation**: Comprehensive scoring with red flag detection and recommendations
- ğŸ›¡ï¸ **Ethical Grounding**: Built-in safeguards prevent fabrication with evidence-based optimization

### Real-Time Streaming & Event System
- ğŸ”„ **Live Streaming**: Real-time progress updates via Server-Sent Events (SSE)
- ğŸ’¾ **Event Persistence**: All agent events stored in SQLite for replay and recovery
- ğŸ”„ **Reconnection Support**: Clients can reconnect and resume from the last known event
- ğŸ’¡ **Parallel Insight Extraction**: Real-time chunk-by-chunk streaming with dedicated insight model
- ğŸ“ˆ **Stream History**: Configurable event history for debugging and monitoring

### Advanced LLM Support
- ğŸ§  **Multi-Provider LLM Support**: OpenRouter, Google Gemini, Cerebras, Zenmux, LongCat, and more
- ğŸšï¸ **Per-Agent Model Configuration**: Individual model and temperature settings for each agent
- âš™ï¸ **Advanced Parameters**: Support for top_p, top_k, frequency_penalty, presence_penalty, seed, and stop sequences
- ğŸ’° **Cost Tracking**: Real-time cost calculation with input, output, and thinking token breakdowns
- ğŸ“ **Model Registry**: Capability-based model selection with provider-specific optimizations

### Resume Processing
- ğŸ“„ **Multi-format Support**: Upload PDF, DOCX, or images with intelligent parsing
- ğŸ”— **URL Ingestion**: Fetch job postings directly from URLs using Exa API
- ğŸ“¥ **Export Options**: Download optimized resumes in DOCX, PDF, or HTML format
- ğŸ“ƒ **Flexible Page Constraints**: 2-3 page resumes supported with intelligent content optimization

### Application Management
- ğŸ’¾ **Application Tracking**: Save and compare multiple applications with version history
- ğŸ¯ **Profile Persistence**: Profile data stored in database for reuse across applications
- ğŸ¨ **Modern UI**: Beautiful React interface with real-time streaming updates and smooth animations
- ğŸ‘¥ **Rate Limiting**: Built-in free tier management (5 runs per client) with abuse prevention

### Production-Ready Features
- â˜ï¸ **Cloud-Native**: Deployed on Cloud Run (backend) and Vercel (frontend)
- ğŸ” **Secret Management**: Secure API key handling via Secret Manager
- ğŸ›¡ï¸ **Error Recovery**: Distributed systems hardening with state persistence
- ğŸ“Š **Monitoring**: Comprehensive logging and event tracking

## Tech Stack

### Backend
- **Python 3.11+** with FastAPI
- **Database**: SQLite with automatic schema migrations (ephemeral in Cloud Run)
- **LLM Orchestration**: Multi-provider model registry with capability-based routing
- **Providers**: OpenRouter, Google Gemini, Cerebras, Zenmux, LongCat, Exa API
- **File Processing**: PDF extraction, DOCX generation, HTML parsing
- **Streaming**: Server-Sent Events with event persistence and replay
- **Cost Tracking**: Real-time pricing calculation with token-based billing

### Frontend
- **React 19** + **TypeScript** + **Vite**
- **Styling**: TailwindCSS v4 + shadcn/ui 2025 component library
- **Design System**: 200+ tokens, CSS variables, runtime theming
- **Animations**: Framer Motion with reduced motion support
- **Forms**: React Hook Form + Zod validation
- **State Management**: LocalStorage + IndexedDB for offline support
- **API Client**: SSE with reconnection and event replay

## Project Structure

```
resume-optimizer/
â”œâ”€â”€ backend/                       # Python FastAPI server
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ agents/               # ğŸ¤– AI agent implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py                   # Base agent class
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_agent.py          # Profile enrichment (optional)
â”‚   â”‚   â”‚   â”œâ”€â”€ job_analyzer.py           # Agent 1: Job analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ resume_optimizer.py       # Agent 2: Strategy generation
â”‚   â”‚   â”‚   â”œâ”€â”€ optimizer_implementer.py  # Agent 3: Implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ validator.py              # Agent 4: Validation & scoring
â”‚   â”‚   â”‚   â”œâ”€â”€ github_projects_agent.py  # GitHub curation (separate)
â”‚   â”‚   â”‚   â”œâ”€â”€ polish.py                 # Agent 5: Final polish
â”‚   â”‚   â”‚   â””â”€â”€ renderer.py               # Document rendering
â”‚   â”‚   â”œâ”€â”€ api/                  # ğŸ”Œ Multi-provider LLM clients
â”‚   â”‚   â”‚   â”œâ”€â”€ cerebras.py
â”‚   â”‚   â”‚   â”œâ”€â”€ client_factory.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini.py
â”‚   â”‚   â”‚   â”œâ”€â”€ longcat.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_registry.py         # Model capability registry
â”‚   â”‚   â”‚   â”œâ”€â”€ multiprovider.py
â”‚   â”‚   â”‚   â”œâ”€â”€ openrouter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.py                # Cost tracking system
â”‚   â”‚   â”‚   â”œâ”€â”€ types.py
â”‚   â”‚   â”‚   â””â”€â”€ zenmux.py
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ services/         # ğŸ“‹ Service layer
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ export.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ persistence.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ validation_parser.py
â”‚   â”‚   â”‚   â”œâ”€â”€ streaming.py              # Stream manager
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database/             # ğŸ’¾ SQLite database layer
â”‚   â”‚   â”‚   â”œâ”€â”€ db.py
â”‚   â”‚   â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ middleware/           # ğŸ”’ Error handling
â”‚   â”‚   â”‚   â”œâ”€â”€ error_interceptor.py
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/               # ğŸ›£ï¸ API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ recovery.py
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ services/             # ğŸ”§ Core services
â”‚   â”‚   â”‚   â””â”€â”€ recovery_service.py
â”‚   â”‚   â”œâ”€â”€ streaming/            # ğŸŒŠ SSE streaming infrastructure
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ events.py                 # Event types
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py                # Stream manager with history
â”‚   â”‚   â”‚   â”œâ”€â”€ run_store.py              # Run persistence
â”‚   â”‚   â”‚   â”œâ”€â”€ insight_extractor.py      # Insight extraction
â”‚   â”‚   â”‚   â””â”€â”€ insight_listener.py       # Parallel processing
â”‚   â”‚   â”œâ”€â”€ templates/            # ğŸ“ HTML templates
â”‚   â”‚   â”‚   â”œâ”€â”€ resume_basic.html
â”‚   â”‚   â”‚   â”œâ”€â”€ resume_structured.html
â”‚   â”‚   â”‚   â””â”€â”€ resume_styled.html
â”‚   â”‚   â””â”€â”€ utils/                # ğŸ› ï¸ Utilities
â”‚   â”‚       â”œâ”€â”€ docx_generator.py
â”‚   â”‚       â”œâ”€â”€ error_classification.py
â”‚   â”‚       â”œâ”€â”€ file_handler.py
â”‚   â”‚       â”œâ”€â”€ pdf_extractor.py
â”‚   â”‚       â”œâ”€â”€ pricing_calculator.py
â”‚   â”‚       â”œâ”€â”€ prompt_loader.py          # Prompt loader system
â”‚   â”‚       â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ prompts/                  # ğŸ“ Agent prompt files
â”‚   â”‚   â”œâ”€â”€ insights/             # Real-time insight prompts
â”‚   â”‚   â”‚   â”œâ”€â”€ content_analyzer.md
â”‚   â”‚   â”‚   â”œâ”€â”€ content_implementer.md
â”‚   â”‚   â”‚   â”œâ”€â”€ content_optimizer.md
â”‚   â”‚   â”‚   â”œâ”€â”€ quality_polish.md
â”‚   â”‚   â”‚   â””â”€â”€ quality_validator.md
â”‚   â”‚   â”œâ”€â”€ agent1_job_analyzer.md
â”‚   â”‚   â”œâ”€â”€ agent2_resume_optimizer.md
â”‚   â”‚   â”œâ”€â”€ agent3_optimizer_implementer.md
â”‚   â”‚   â”œâ”€â”€ agent5_polish.md
â”‚   â”‚   â””â”€â”€ profile_agent.md
â”‚   â”œâ”€â”€ .env.cloudrun            # Cloud Run environment template
â”‚   â”œâ”€â”€ .env.example             # Local environment template
â”‚   â”œâ”€â”€ deploy.sh                # Deployment script
â”‚   â”œâ”€â”€ Procfile                 # Cloud Run web process
â”‚   â”œâ”€â”€ pyproject.toml           # Python dependencies (uv)
â”‚   â”œâ”€â”€ requirements.txt         # Legacy pip dependencies
â”‚   â”œâ”€â”€ runtime.txt              # Python version for Cloud Run
â”‚   â””â”€â”€ server.py                # FastAPI application entry
â”œâ”€â”€ frontend/                     # React + Vite application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/           # âš›ï¸ React components
â”‚   â”‚   â”‚   â”œâ”€â”€ shared/           # Shared UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ tabs/             # Tabbed interface components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/               # shadcn/ui components
â”‚   â”‚   â”‚   â”œâ”€â”€ DownloadHero.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ExportModal.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ InputScreen.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProcessingScreen.tsx
â”‚   â”‚   â”‚   â””â”€â”€ RevealScreen.tsx
â”‚   â”‚   â”œâ”€â”€ design-system/        # ğŸ¨ Design tokens and theme
â”‚   â”‚   â”‚   â”œâ”€â”€ animations/       # Framer Motion variants
â”‚   â”‚   â”‚   â”œâ”€â”€ docs/             # Design system documentation
â”‚   â”‚   â”‚   â”œâ”€â”€ forms/            # Form validation (React Hook Form + Zod)
â”‚   â”‚   â”‚   â”œâ”€â”€ theme/            # Brand config and presets
â”‚   â”‚   â”‚   â””â”€â”€ tokens/           # 200+ design tokens
â”‚   â”‚   â”œâ”€â”€ hooks/                # ğŸª Custom React hooks
â”‚   â”‚   â”œâ”€â”€ lib/                  # ğŸ› ï¸ Utilities
â”‚   â”‚   â”œâ”€â”€ services/             # ğŸŒ API and storage
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts            # SSE client with reconnection
â”‚   â”‚   â”‚   â””â”€â”€ storage/
â”‚   â”‚   â”‚       â”œâ”€â”€ IndexedDBAdapter.ts
â”‚   â”‚   â”‚       â”œâ”€â”€ LocalStorageAdapter.ts
â”‚   â”‚   â”‚       â””â”€â”€ StateManager.ts
â”‚   â”‚   â”œâ”€â”€ types/                # ğŸ“ TypeScript types
â”‚   â”‚   â”œâ”€â”€ utils/                # ğŸ”§ Utilities
â”‚   â”‚   â”‚   â””â”€â”€ clientId.ts       # Client ID generation
â”‚   â”‚   â”œâ”€â”€ App.tsx               # Root component
â”‚   â”‚   â”œâ”€â”€ constants.ts          # Application constants
â”‚   â”‚   â”œâ”€â”€ index.css             # Global styles (CSS variables)
â”‚   â”‚   â”œâ”€â”€ index.tsx             # Entry point
â”‚   â”‚   â”œâ”€â”€ types.ts              # Global types
â”‚   â”‚   â””â”€â”€ vite-env.d.ts         # Vite environment types
â”‚   â”œâ”€â”€ .env.example             # Frontend environment template
â”‚   â”œâ”€â”€ .env.production          # Production environment
â”‚   â”œâ”€â”€ components.json          # shadcn/ui configuration
â”‚   â”œâ”€â”€ DESIGN_SYSTEM.md         # Design system guide
â”‚   â”œâ”€â”€ IMPLEMENTATION_PROGRESS.md
â”‚   â”œâ”€â”€ REFACTORING_COMPLETE.md
â”‚   â”œâ”€â”€ REFACTORING_SUMMARY.md
â”‚   â”œâ”€â”€ package.json             # Node dependencies
â”‚   â”œâ”€â”€ tailwind.config.js       # Tailwind configuration
â”‚   â”œâ”€â”€ tsconfig.json            # TypeScript configuration
â”‚   â”œâ”€â”€ vercel.json              # Vercel deployment config
â”‚   â””â”€â”€ vite.config.ts           # Vite configuration
â”œâ”€â”€ docs/                         # ğŸ“š Documentation
â”‚   â”œâ”€â”€ architecture/             # Architecture documents
â”‚   â”œâ”€â”€ integrations/             # Integration guides
â”‚   â”œâ”€â”€ setup/                    # Setup and configuration
â”‚   â”œâ”€â”€ specs/                    # Technical specifications
â”‚   â”‚   â”œâ”€â”€ authentication-and-metering/
â”‚   â”‚   â”œâ”€â”€ deployment/           # Cloud Run/Vercel deployment specs
â”‚   â”‚   â”œâ”€â”€ distributed-streaming-hardening/
â”‚   â”‚   â”œâ”€â”€ experimentation-tracking/
â”‚   â”‚   â””â”€â”€ llm-provider-parameters/
â”‚   â”œâ”€â”€ troubleshooting/          # Troubleshooting guides
â”‚   â”œâ”€â”€ DOCUMENTATION_INDEX.md   # Documentation navigation
â”‚   â””â”€â”€ README.md                # Docs overview
â”œâ”€â”€ exports/                      # Generated resumes storage
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”œâ”€â”€ AGENTS.md                    # Agent development guide
â”œâ”€â”€ CLAUDE.md                    # Claude-specific notes
â”œâ”€â”€ DEPLOYMENT.md                # Deployment guide
â”œâ”€â”€ README.md                    # This file
â””â”€â”€ start.sh / start.bat         # Local development scripts
```

## Documentation

ğŸ“š **[View Complete Documentation](./docs/DOCUMENTATION_INDEX.md)** - Complete index of all documentation organized by purpose.

**Quick Links:**
- [Setup Guide](./docs/setup/SETUP.md) - Comprehensive installation and configuration
- [Gemini Setup Guide](./docs/setup/GEMINI_SETUP.md) - Google Gemini API configuration
- [Design System Guide](./frontend/DESIGN_SYSTEM.md) - Frontend design system documentation
- [Agent Development Guide](./AGENTS.md) - Complete project overview for AI agents
- [Architecture Design Pattern](./docs/architecture/AGENTS_DESIGN_PATTERN.md) - 5-agent pipeline architecture
- [Integration Summary](./docs/integrations/INTEGRATION_SUMMARY.md) - Full-stack integration overview
- [Streaming Specification](./docs/specs/streaming_specification.md) - Real-time streaming architecture
- [Deployment Guides](./docs/specs/deployment/) - Cloud Run, Vercel, hybrid deployment options
- [Troubleshooting](./docs/troubleshooting/) - Common issues and solutions

## Setup

### Prerequisites

- **Python 3.11+** (with `uv` package manager recommended)
- **Node.js 20+** with npm
- API keys for at least one LLM provider (OpenRouter, Gemini, Cerebras, etc.)

### Backend Setup

1. **Navigate to the backend directory:**
```bash
cd backend
```

2. **Create and activate virtual environment (using uv):**
```bash
uv venv
# Windows (CMD): .\.venv\Scripts\activate
# Windows (PowerShell): .\.venv\Scripts\Activate.ps1
# macOS/Linux: source .venv/bin/activate
```

3. **Install dependencies:**
```bash
uv pip install -r requirements.txt
```

4. **Create environment file:**
```bash
cp .env.example .env  # or copy .env.example .env on Windows
```

5. **Configure your API keys in `.env`:**

**Required (minimum one provider):**
```bash
OPENROUTER_API_KEY=your_openrouter_key_here
# or
GEMINI_API_KEY=your_gemini_key_here
```

**Optional (additional providers):**
```bash
CEREBRAS_API_KEY=your_cerebras_key_here
EXA_API_KEY=your_exa_key_here
ZENMUX_API_KEY=your_zenmux_key_here
LONGCAT_API_KEY=your_longcat_key_here
```

**Advanced Configuration (per-agent models):**
```bash
# Individual models for each agent (defaults shown)
ANALYZER_MODEL=gemini::gemini-2.5-pro
OPTIMIZER_MODEL=openrouter::openai/gpt-5.1
IMPLEMENTER_MODEL=openrouter::anthropic/claude-sonnet-4.5
VALIDATOR_MODEL=gemini::gemini-2.5-pro
POLISH_MODEL=openrouter::anthropic/claude-sonnet-4.5
PROFILE_MODEL=openrouter::anthropic/claude-sonnet-4.5
INSIGHT_MODEL=openrouter::x-ai/grok-4-fast
```

**Per-Agent Temperature Settings:**
```bash
ANALYZER_TEMPERATURE=0.6
OPTIMIZER_TEMPERATURE=1
IMPLEMENTER_TEMPERATURE=0.6
VALIDATOR_TEMPERATURE=0.2
PROFILE_TEMPERATURE=0.6
POLISH_TEMPERATURE=0.7
```

**Rate Limiting:**
```bash
# Maximum free runs per client (default: 5)
MAX_FREE_RUNS=5
```

**Database:**
```bash
# SQLite database path (Cloud Run uses /tmp for ephemeral storage)
DATABASE_PATH=./data/applications.db
```

**CORS Configuration:**
```bash
# Comma-separated list of allowed origins (use * for development)
CORS_ORIGINS=*
```

### Frontend Setup

1. **Navigate to the frontend directory:**
```bash
cd frontend
```

2. **Install dependencies:**
```bash
npm ci  # or npm install
```

3. **Create environment file:**
```bash
cp .env.example .env.local
# On Windows: copy .env.example .env.local
```

4. **Configure frontend environment variables:**

```bash
# Backend API URL (development)
VITE_API_URL=http://localhost:8000

# Optional: Brand customization
# VITE_BRAND_NAME=Resume Optimizer
# VITE_PRIMARY_COLOR=#0274BD
# VITE_ACCENT_COLOR=#F57251
```

**Note:** In production (Vercel), `VITE_API_URL` should be set to `/api` to use the Vercel rewrite proxy.

## Running the Application

### Quick Start (Both Services)

**Windows:**
```bash
.\start.bat
```

**macOS/Linux:**
```bash
bash ./start.sh
```

### Individual Services

**Backend:**
```bash
cd backend
python server.py
```

**Alternative (with hot reload):**
```bash
cd backend
uvicorn server:app --reload --host 0.0.0.0 --port 8000
```

**Frontend:**
```bash
cd frontend
npm run dev
```

**Preview production build:**
```bash
cd frontend
npm run build
npm run preview
```

### Accessing the Application

- **Frontend**: http://localhost:5173 (Vite default)
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs (Swagger UI)

## Usage

### ğŸš€ Agent-Powered Optimization Workflow

1. **ğŸ“¤ Upload Resume**: Upload your resume in PDF, DOCX, TXT, or HTML format
2. **ğŸ”— Provide Job Details**: Paste the job posting URL (auto-fetched via Exa API) or enter text manually
3. **ğŸ¯ Optional Profile Enhancement**: Add LinkedIn URL and/or GitHub username for contextual evidence
4. **ğŸ¤– Agent Pipeline Execution**: The sequential pipeline processes your application with real-time updates:
   - **Step 0 - Profile Building** (Optional): Creates evidence index from LinkedIn/GitHub
   - **Step 1 - Job Analysis**: Extracts requirements, role signals, and keywords
   - **Step 2 - Strategy Generation**: Creates evidence-based optimization plan  
   - **Step 3 - Implementation**: Applies strategic changes to your resume
   - **Step 4 - Validation**: Evaluates accuracy, scores match (1-100), and flags issues
   - **Step 5 - Polish**: Refines output for professional presentation with DOCX-ready formatting

5. **ğŸ“Š Review Results**: Compare before/after versions with detailed validation scores and red flag analysis
6. **ğŸ“ˆ Cost Tracking**: View real-time cost estimates for the optimization process
7. **ğŸ’¾ Save & Export**: Download optimized resume in DOCX, PDF, or HTML format
8. **ğŸ”„ Reconnect Anytime**: Pipeline state is persisted, allowing reconnection and resuming from any point

### Rate Limiting & Free Tier

The application includes built-in rate limiting to prevent abuse:
- **Free Tier**: 5 resume generations per client (browser)
- **Client Tracking**: Uses LocalStorage to maintain client ID across sessions
- **Rate Limit Response**: HTTP 429 with `Retry-After` header when limit exceeded
- **Configurable**: Set `MAX_FREE_RUNS` environment variable to adjust limits

### Event Persistence & Replay

All pipeline events are persisted to SQLite, enabling:
- **Reconnection**: Resume from the last known event after network interruption
- **Event Replay**: Replay previous runs for debugging or demonstration
- **State Recovery**: Serverless containers can recover state after restart
- **Snapshot Access**: Get current pipeline state at any time via `/api/jobs/{id}/snapshot`

## API Endpoints

### Main Pipeline
- `POST /api/pipeline/start` - Start full pipeline with streaming
  - **Request**: `{ resume, job_posting_url, job_posting_text, client_id }`
  - **Response**: Job ID for streaming
  - **Headers**: `X-Client-ID` for rate limiting
- `GET /api/jobs/{job_id}/stream` - Server-Sent Events for real-time progress
  - **Features**: Event persistence, reconnection support, replay capability
  - **Parameters**: `?after_event_id={last_event_id}` for resuming
- `GET /api/jobs/{job_id}/snapshot` - Get current pipeline state
  - **Includes**: Agent outputs, validation scores, generated resume, run metadata

### Core Endpoints
- `POST /api/upload-resume` - Upload and parse resume file
  - **Supports**: PDF, DOCX, TXT, HTML
  - **Returns**: Parsed text content
- `POST /api/scan-resume` - Scan resume for detailed structure
  - **Extracts**: Contact info, sections, chronology, achievements
- `POST /api/analyze-job` - Analyze job posting (Agent 1)
  - **Input**: URL (via Exa API) or raw text
  - **Output**: Requirements, role signals, keywords
- `POST /api/optimize-resume` - Generate optimization strategy (Agent 2)
  - **Output**: Evidence-based optimization plan
- `POST /api/implement` - Apply optimizations (Agent 3)
  - **Output**: Optimized resume content
- `POST /api/validate` - Validate resume (Agent 4)
  - **Output**: Multi-dimensional scores, red flags, recommendations
- `POST /api/polish` - Final polish (Agent 5)
  - **Output**: DOCX-ready resume with formatting guidance

### Export & Download
- `GET /api/export/{id}` - Export optimized resume
  - **Formats**: DOCX, PDF (via conversion)
  - **Includes**: Formatted document with styles
- `GET /api/download/{filename}` - Download exported file

### Application Management
- `GET /api/applications` - List all applications
  - **Response**: Array of application metadata
- `GET /api/application/{id}` - Get application details
  - **Includes**: Full pipeline results, scores, generated resume

### GitHub Integration
- `POST /api/curate-github` - Curate relevant GitHub projects
  - **Input**: GitHub username
  - **Output**: Curated project list with descriptions

### Recovery & Health
- `GET /api/health` - Health check endpoint
- `GET /api/recovery/{run_id}/status` - Check recovery status
- `POST /api/recovery/{run_id}/resume` - Resume from checkpoint

### Event Streaming
All SSE events include:
- `event`: Event type (e.g., `job_status`, `agent_step`, `insight`)
- `id`: Monotonically increasing event ID
- `data`: JSON payload
- `retry`: Reconnection timeout

**Event Types:**
- `job_status` - Job state changes
- `agent_step` - Agent execution progress
- `agent_chunk` - Real-time agent output chunks
- `insight` - Extracted insights
- `metrics` - Cost and performance metrics
- `done` - Pipeline completion

## Development

### Code Quality

**Backend (Python):**
```bash
cd backend

# Format code (requires black and ruff)
black .
ruff check . --fix
```

**Frontend (TypeScript/React):**
```bash
cd frontend

# Lint code (ESLint configured)
npm run lint

# Type check (no compilation needed)
npx tsc --noEmit
```

### Testing

**Backend Unit Tests:**
```bash
cd backend
python -m pytest
```

**Frontend Tests:**
```bash
cd frontend
# TODO: Add Vitest for unit tests and Playwright/Cypress for E2E
# npm test (when test runner is configured)
```

### Frontend Design System

The application uses a comprehensive design system built on **shadcn/ui (2025)** with modern tooling:

**Key Features:**
- **200+ Design Tokens**: Colors, typography, spacing, shadows, borders, animations in `@/design-system/tokens`
- **shadcn Components**: 10+ accessible, customizable components (Button, Card, Badge, Dialog, Input, Tabs, Tooltip)
- **WCAG 2.1 AA Compliance**: Built-in accessibility features including keyboard navigation and reduced motion
- **Responsive Design**: Mobile-first with breakpoint hooks (`useIsMobile`, `useBreakpoint`)
- **Motion System**: 20+ Framer Motion variants with `useReducedMotion` hook
- **Brand Customization**: White-labeling via CSS variables and `applyBrandConfig()`
- **Form Validation**: React Hook Form + Zod integration with reusable field wrappers

**Color System:**
- CSS variables (`--primary: 199 97% 42%`, `--accent: 14 88% 63%`) defined in `src/index.css`
- Tailwind utilities reference CSS variables: `bg-primary`, `text-primary`, `border-primary/90`
- Runtime theming via `VITE_PRIMARY_COLOR`, `VITE_BRAND_NAME` environment variables
- **Never use hardcoded hex colors** - always use Tailwind utilities

**Component Usage:**
```typescript
import { Button } from '@/components/ui/button';
import { useFormValidation } from '@/design-system/forms';
import { slideUpVariants, useReducedMotion } from '@/design-system/animations';
```

**Documentation:**
- Design System Guide: [`frontend/DESIGN_SYSTEM.md`](./frontend/DESIGN_SYSTEM.md)
- Component Docs: [`frontend/src/design-system/docs/README.md`](./frontend/src/design-system/docs/README.md)
- shadcn/ui Docs: https://ui.shadcn.com/

### Continuous Integration

**TODO:** Add GitHub Actions for:
- Backend: black, ruff, pytest
- Frontend: ESLint, TypeScript type checking, test runner
- Build verification for both frontend and backend

## ğŸ›¡ï¸ Ethical Guidelines & Validation

### Multi-Layer Safety System

All agents follow strict ethical guidelines with **deterministic validation**:

- **ğŸš« No Fabrication Rule**: Never create false employers, titles, dates, or metrics
- **ğŸ“ Evidence-Based Approach**: All optimizations backed by actual experience
- **âš ï¸ Conservative Phrasing**: Uses cautious language when uncertain
- **âœ… Validation Layer**: Agent 4 performs comprehensive fact-checking and scoring
- **ğŸ” Red Flag Detection**: Identifies potentially unsupported claims
- **ğŸ¯ Final Review**: Agent 5 removes any unsupported claims before output

### Validation Scoring System

Agent 4 provides multi-dimensional analysis:
- **ğŸ“Š Match Score**: Overall alignment with job requirements
- **âš ï¸ Risk Assessment**: Red flags for potentially exaggerated claims
- **ğŸ“ˆ Improvement Metrics**: Quantified enhancement areas
- **ğŸ¯ Recommendation Engine**: Specific suggestions for improvement

**Our Philosophy**: Present your TRUE qualifications optimally, not create fictional credentials.

## Troubleshooting

### Backend Issues

**Import errors:**
- Ensure virtual environment is activated
- Run `python -m pip install -r requirements.txt` to verify dependencies

**API errors:**
- Verify API keys in `.env` file are correct
- Check provider-specific error messages in logs
- Ensure model names match supported providers (see `backend/src/api/model_registry.py`)

**Database errors:**
- Ensure `DATABASE_PATH` directory exists
- Check file permissions on SQLite database
- In Cloud Run, remember data is ephemeral (use `/tmp`)

**SSE/streaming issues:**
- SSE buffering in Cloud Run requires proper configuration (see deployment guide)
- Check Cloud Run minimum instance settings to prevent cold starts
- Enable event persistence for reliability

**Rate limiting errors:**
- Check `MAX_FREE_RUNS` environment variable
- Verify client ID is being sent in `X-Client-ID` header
- Clear browser LocalStorage if client ID issues persist

### Frontend Issues

**Connection errors:**
- Ensure backend is running on the correct port (default: 8000)
- Check `VITE_API_URL` in frontend `.env.local`
- Verify CORS settings in backend `.env`

**Build errors:**
- Delete `node_modules` and `package-lock.json`
- Run `npm ci` to reinstall clean dependencies
- Check Node.js version (requires 20+)

**Streaming/SSE errors:**
- Check browser console for connection errors
- Verify backend `/api/jobs/{id}/stream` endpoint is accessible
- Ensure Cloud Run is configured for streaming (padding enabled)

**Styling issues:**
- Never use hardcoded hex colors (e.g., `text-[#0274BD]`)
- Always use Tailwind utilities that reference CSS variables (e.g., `text-primary`)
- Check CSS variables are defined in `frontend/src/index.css`
- Verify `applyBrandConfig()` is called in `frontend/src/index.tsx`

### Common Solutions

**CORS errors in development:**
```bash
# In backend .env
CORS_ORIGINS=*
```

**Cloud Run SSE buffering:**
- Events include padding to force buffer flushes
- Configure minimum instances to reduce cold starts
- Use event persistence for reliability

**Model errors:**
- Check model supports required capabilities (`supports_files`, `supports_images`)
- Some models don't support temperature (e.g., GPT-5.1)
- Verify API keys have sufficient quota

## ğŸš€ Deployment

The application is production-ready and deployed using modern cloud platforms:

### Current Deployment

- **Backend**: Google Cloud Run (us-central1)
  - **URL**: https://resume-optimizer-backend-784455190453.us-central1.run.app
  - **Features**: Auto-scaling, SSE streaming support, Secret Manager integration
- **Frontend**: Vercel
  - **URL**: https://resume-optimizer-eosin.vercel.app
  - **Features**: Global CDN, zero-config deployments, API proxy rewrite
- **Database**: SQLite (Cloud Run ephemeral storage at `/tmp`)
  - **Note**: Data persists across requests but is lost on container restart
  - **Future**: Migration to Cloud SQL PostgreSQL planned

### Cloud Run Deployment Highlights

âœ… **SSE Streaming**: Configured with event persistence for reliable real-time updates
âœ… **Secret Management**: API keys stored in Secret Manager, not environment variables
âœ… **Rate Limiting**: Built-in protection with configurable free tier
âœ… **Event Replay**: Clients can reconnect and resume from last known event
âœ… **Cost Tracking**: Real-time cost calculation with multi-provider support

### Deployment Architecture

```
User Browser â†’ Vercel CDN â†’ Cloud Run Backend
                   â†“
            API Proxy Rewrite (/api/*)
                   â†“
         SQLite Database (/tmp/applications.db)
```

**Key Features:**
- Same-origin requests (no CORS configuration needed)
- Automatic SSL certificate provisioning
- Global CDN for frontend assets
- Serverless scaling for backend

### Production Considerations

**Database Persistence:**
Current SQLite setup is ephemeral. For production persistence:
1. Create Cloud SQL PostgreSQL instance
2. Update `backend/src/database/db.py` connection logic
3. Set environment variables for Cloud SQL

**Monitoring:**
- Cloud Run logs available in Google Cloud Console
- Vercel analytics and monitoring dashboard
- Application logs include cost tracking and performance metrics

**Scaling:**
- Cloud Run auto-scales based on request volume
- Minimum instances recommended for streaming reliability
- Event persistence ensures state survives container restarts

See [DEPLOYMENT.md](./DEPLOYMENT.md) for detailed deployment instructions and troubleshooting.

## License

Proprietary - All rights reserved

